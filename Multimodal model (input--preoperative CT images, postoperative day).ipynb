{"cells":[{"cell_type":"code","execution_count":null,"id":"81ce4b47","metadata":{"id":"81ce4b47"},"outputs":[],"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix, recall_score\n","import matplotlib.pyplot as plt\n","import pickle"]},{"cell_type":"markdown","source":["## Load training and validation data with data augmentation and test data"],"metadata":{"id":"zm1vcM3svzjX"},"id":"zm1vcM3svzjX"},{"cell_type":"code","execution_count":null,"id":"TsiKkbbv3OZy","metadata":{"id":"TsiKkbbv3OZy"},"outputs":[],"source":["# Load the .npz file containing preprocessed data\n","loaded_data = np.load(\"PATH1.npz\")  # Replace with actual file path\n","\n","# Access individual datasets\n","x_train_val_image = loaded_data[\"x_train_val_image\"]  # 3D image data for training/validation\n","x_train_val_table = loaded_data[\"x_train_val_table\"]  # Tabular clinical data\n","y_train_val = loaded_data[\"y_train_val\"]  # Labels\n","\n","# Check the original dataset shape\n","print(\"Before shuffle:\")\n","print(x_train_val_image.shape, x_train_val_table.shape, y_train_val.shape)\n","\n","# Ensure all arrays have the same first dimension\n","assert x_train_val_image.shape[0] == x_train_val_table.shape[0] == y_train_val.shape[0], \"Shapes mismatch!\"\n","\n","# Shuffle the dataset while maintaining correspondence\n","indices = np.arange(x_train_val_image.shape[0])  # Create an index array\n","np.random.shuffle(indices)  # Shuffle indices\n","\n","# Apply shuffled indices to all arrays\n","x_train_val_image = x_train_val_image[indices]\n","x_train_val_table = x_train_val_table[indices]\n","y_train_val = y_train_val[indices]\n","\n","# Print dataset shape after shuffling\n","print(\"After shuffle:\")\n","print(x_train_val_image.shape, x_train_val_table.shape, y_train_val.shape)\n","\n","# Load test dataset\n","x_test_image = loaded_data[\"x_test_image\"]\n","x_test_table = loaded_data[\"x_test_table\"]\n","y_test = loaded_data[\"y_test\"]\n","\n","# Print test dataset shape\n","print(x_test_image.shape, x_test_table.shape, y_test.shape)"]},{"cell_type":"markdown","source":["## Load training and validation data without data augmentation (rawTrainVal set)"],"metadata":{"id":"PliqqLZ0wQCh"},"id":"PliqqLZ0wQCh"},{"cell_type":"code","execution_count":null,"id":"O1qs-qAuvEU7","metadata":{"id":"O1qs-qAuvEU7"},"outputs":[],"source":["# Load the .npz file\n","loaded_data = np.load(\"PATH2.npz\")  # Replace with actual file path\n","\n","# Access individual datasets\n","x_train_val_image_raw = loaded_data[\"x_train_val_image\"]  # Non-augmented images\n","x_train_val_table_raw = loaded_data[\"x_train_val_table\"]  # Non-augmented clinical data\n","y_train_val_raw = loaded_data[\"y_train_val\"]  # Labels for non-augmented data\n","\n","# Verify dataset shapes\n","print(x_train_val_image_raw.shape, x_train_val_table_raw.shape, y_train_val_raw.shape)"]},{"cell_type":"markdown","id":"jyNl3a1rZNje","metadata":{"id":"jyNl3a1rZNje"},"source":["#  **Training and validation**"]},{"cell_type":"code","execution_count":null,"id":"kdZf0V9LlSeZ","metadata":{"id":"kdZf0V9LlSeZ"},"outputs":[],"source":["# Number of cross-validation folds\n","num_folds = 5\n","\n","# Define folder for saving model checkpoints\n","checkpoint_folder = \"PATH3\"  # Replace with actual directory path"]},{"cell_type":"markdown","source":["## Define tabular model for postoperative days (non-imaging branch)"],"metadata":{"id":"jlfDEGOW0UfC"},"id":"jlfDEGOW0UfC"},{"cell_type":"code","execution_count":null,"id":"opD1WusNnq2D","metadata":{"id":"opD1WusNnq2D"},"outputs":[],"source":["fold = 0  # Initialize fold index\n","\n","def model_tabular(number_of_items=x_train_val_table.shape[1], fold=fold):\n","    \"\"\"\n","    Define a simple neural network for tabular clinical data.\n","    \"\"\"\n","    inputs = keras.Input((number_of_items,), name=f\"tabular_input_fold_{fold}\")  # Input layer\n","\n","    outputs = inputs  # Identity mapping (modify for deeper models)\n","\n","    model = keras.Model(inputs, outputs, name=f\"TabularModel_Fold_{fold}\")  # Define model\n","\n","    return model\n","\n","# Set random seed for reproducibility\n","tf.random.set_seed(42)\n","\n","# Create and print model summary\n","tabular_model = model_tabular()\n","tabular_model.summary()"]},{"cell_type":"markdown","source":["## Define 3D CNN model for preoperative CT images (imaging branch)"],"metadata":{"id":"SFJaPi8e3K6_"},"id":"SFJaPi8e3K6_"},{"cell_type":"code","execution_count":null,"id":"cff311fb","metadata":{"id":"cff311fb","scrolled":true},"outputs":[],"source":["def model_image(height=x_train_val_image.shape[1], width=x_train_val_image.shape[2], number_of_slices=x_train_val_image.shape[3], fold=fold):\n","    \"\"\"\n","    Define a 3D CNN model for medical image analysis.\n","    \"\"\"\n","    inputs = keras.Input((height, width, number_of_slices, 1), name=f\"image_input_fold_{fold}\")  # Input layer\n","\n","    # Convolutional layers\n","    l = layers.Conv3D(filters=64, kernel_size=3, kernel_initializer=\"he_normal\", name=f\"conv3d_1_fold_{fold}\")(inputs)\n","    l = layers.BatchNormalization(name=f\"batch_norm_1_fold_{fold}\")(l)\n","    l = layers.Activation(\"relu\", name=f\"activation_1_fold_{fold}\")(l)\n","    l = layers.MaxPool3D(pool_size=2, name=f\"maxpool_1_fold_{fold}\")(l)\n","\n","    l = layers.Conv3D(filters=64, kernel_size=3, kernel_initializer=\"he_normal\", name=f\"conv3d_2_fold_{fold}\")(l)\n","    l = layers.BatchNormalization(name=f\"batch_norm_2_fold_{fold}\")(l)\n","    l = layers.Activation(\"relu\", name=f\"activation_2_fold_{fold}\")(l)\n","    l = layers.MaxPool3D(pool_size=2, name=f\"maxpool_2_fold_{fold}\")(l)\n","\n","    l = layers.Conv3D(filters=128, kernel_size=3, kernel_initializer=\"he_normal\", name=f\"conv3d_3_fold_{fold}\")(l)\n","    l = layers.BatchNormalization(name=f\"batch_norm_3_fold_{fold}\")(l)\n","    l = layers.Activation(\"relu\", name=f\"activation_3_fold_{fold}\")(l)\n","    l = layers.MaxPool3D(pool_size=2, name=f\"maxpool_3_fold_{fold}\")(l)\n","\n","    l = layers.Conv3D(filters=256, kernel_size=3, kernel_initializer=\"he_normal\", name=f\"conv3d_4_fold_{fold}\")(l)\n","    l = layers.BatchNormalization(name=f\"batch_norm_4_fold_{fold}\")(l)\n","    l = layers.Activation(\"relu\", name=f\"activation_4_fold_{fold}\")(l)\n","    l = layers.MaxPool3D(pool_size=2, name=f\"maxpool_4_fold_{fold}\")(l)\n","\n","    l = layers.GlobalAveragePooling3D(name=f\"global_avg_pool_fold_{fold}\")(l)\n","    l = layers.Dense(units=512, activation=\"relu\", kernel_initializer=\"he_normal\", name=f\"dense_1_fold_{fold}\")(l)\n","    l = layers.Dropout(0.3, name=f\"dropout_1_fold_{fold}\")(l)\n","\n","    outputs = layers.Dense(units=1, activation=\"sigmoid\", name=f\"output_dense_fold_{fold}\")(l)\n","\n","    model = keras.Model(inputs, outputs, name=f\"ImageModel_Fold_{fold}\")\n","    return model\n","\n","tf.random.set_seed(42)\n","image_model = model_image()\n","image_model.summary()"]},{"cell_type":"markdown","source":["## Combine tabular and image models into a multimodal network"],"metadata":{"id":"OQhlWFvS3b6n"},"id":"OQhlWFvS3b6n"},{"cell_type":"code","execution_count":null,"id":"bzqeu07yy-49","metadata":{"id":"bzqeu07yy-49"},"outputs":[],"source":["def multimodal_model(tabular_model, image_model, fold):\n","    \"\"\"\n","    Merge tabular and image models into a single multimodal network.\n","    \"\"\"\n","    tabular_inputs = tabular_model.input\n","    tabular_outputs = tabular_model.output\n","\n","    image_inputs = image_model.input\n","    image_outputs = image_model.output\n","\n","    combined = tf.keras.layers.Concatenate(name=f\"combine_tabular_image_fold_{fold}\")([tabular_outputs, image_outputs])\n","\n","    outputs = tf.keras.layers.Dense(units=1, activation=\"sigmoid\", name=f\"output_fold_{fold}\")(combined)\n","\n","    model = tf.keras.Model(inputs=[tabular_inputs, image_inputs], outputs=outputs, name=f\"MultimodalModel_Fold_{fold}\")\n","    return model\n","\n","tf.random.set_seed(42)\n","model = multimodal_model(tabular_model, image_model, fold)\n","model.summary()"]},{"cell_type":"markdown","source":["## Training visualization, data generation, and cross-validation for the model"],"metadata":{"id":"XoldkkLNGCIe"},"id":"XoldkkLNGCIe"},{"cell_type":"code","source":["# Visualize training process\n","def plot_fold_history(history, fold):\n","    fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n","    for i, metric in enumerate([\"loss\", \"auc\"]):\n","        ax[i].plot(history.history[metric], label=\"Train\")\n","        ax[i].plot(history.history[\"val_\" + metric], label=\"Validation\")\n","        ax[i].set_title(f\"Fold {fold} - {metric.upper()}\")\n","        ax[i].set_xlabel(\"Epochs\")\n","        ax[i].set_ylabel(metric.upper())\n","        ax[i].legend()\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Data generator function\n","def data_generator(x_table, x_image, y, batch_size):\n","    while True:\n","        for start in range(0, len(y), batch_size):\n","            end = start + batch_size\n","            yield (\n","                (x_table[start:end], x_image[start:end]),\n","                y[start:end],\n","            )\n","\n","# Convert generator to a `tf.data.Dataset`\n","def create_dataset(x_table, x_image, y, batch_size):\n","    dataset = tf.data.Dataset.from_generator(\n","        lambda: data_generator(x_table, x_image, y, batch_size),\n","        output_signature=(\n","            (  # Input structure\n","                tf.TensorSpec(shape=(None, x_table.shape[1]), dtype=tf.float32),\n","                tf.TensorSpec(shape=(None, x_image.shape[1], x_image.shape[2], x_image.shape[3], 1), dtype=tf.float32),\n","            ),\n","            tf.TensorSpec(shape=(None,), dtype=tf.float32),  # Output labels\n","        ),\n","    )\n","    return dataset\n","\n","\n","# Initialize the KFold object (do this only once)\n","kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n","\n","# Get the fold splits (this allows you to execute one fold at a time)\n","folds = list(kf.split(x_train_val_table))"],"metadata":{"id":"_6WOjo9s-bCm"},"id":"_6WOjo9s-bCm","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"iJX1C9Lw_ATg","metadata":{"id":"iJX1C9Lw_ATg"},"source":["## Training: fold 0"]},{"cell_type":"code","source":["# Display fold number at training start\n","print(f\"Starting training for Fold {fold}...\")\n","\n","# Split the data for the current fold\n","train_idx, val_idx = folds[fold]\n","x_train_table, x_val_table = x_train_val_table[train_idx], x_train_val_table[val_idx]\n","x_train_image, x_val_image = x_train_val_image[train_idx], x_train_val_image[val_idx]\n","y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n","\n","batch_size=2\n","\n","# Create TensorFlow datasets\n","train_dataset = create_dataset(x_train_table, x_train_image, y_train, batch_size).prefetch(tf.data.AUTOTUNE)\n","val_dataset = create_dataset(x_val_table, x_val_image, y_val, batch_size).prefetch(tf.data.AUTOTUNE)\n","\n","# Clear the default graph and reset the session to free memory\n","tf.keras.backend.clear_session()\n","\n","# Initialize the model\n","tf.random.set_seed(42)\n","model = multimodal_model(tabular_model, image_model, fold)\n","\n","# Compile the model\n","model.compile(\n","    loss=\"binary_crossentropy\",\n","    optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n","    metrics=[tf.keras.metrics.AUC(name=\"auc\"), tf.keras.metrics.Recall(name=\"recall\")]\n",")\n","\n","# Define callbacks\n","checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=os.path.join(checkpoint_folder, f'fold_{fold}_{{epoch:03d}}.keras'),\n","    save_best_only=False\n",")\n","\n","# Train the model\n","history = model.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=50,\n","    steps_per_epoch=len(y_train) // batch_size,\n","    validation_steps=len(y_val) // batch_size,\n","    callbacks=[checkpoint_cb],\n","    verbose=1\n",")\n","\n","# Find the best epoch (based on validation AUC)\n","best_epoch = np.argmax(history.history['val_auc']) + 1\n","best_auc = np.max(history.history['val_auc'])\n","best_model_path = os.path.join(checkpoint_folder, f'fold_{fold}_{best_epoch:03d}.keras')\n","\n","# Save the best model path\n","if os.path.exists(os.path.join(checkpoint_folder, \"best_models.pkl\")):\n","    # Load existing list\n","    with open(os.path.join(checkpoint_folder, \"best_models.pkl\"), \"rb\") as f:\n","        best_models = pickle.load(f)\n","else:\n","    best_models = []\n","\n","best_models.append(best_model_path)\n","\n","# Save the updated list\n","with open(os.path.join(checkpoint_folder, \"best_models.pkl\"), \"wb\") as f:\n","    pickle.dump(best_models, f)\n","\n","# Print results\n","print(f\"Best validation AUC for fold {fold}: {best_auc:.4f} at epoch {best_epoch}\")\n","print(f\"Best model for fold {fold} saved at: {best_model_path}\")\n","\n","# Plot the training history for this fold\n","plot_fold_history(history, fold)"],"metadata":{"id":"h0yR5Yil-jnQ"},"id":"h0yR5Yil-jnQ","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training: fold 1"],"metadata":{"id":"B8Q9ngSjgCRS"},"id":"B8Q9ngSjgCRS"},{"cell_type":"code","source":["fold = 1\n","\n","# Display fold number at training start\n","print(f\"Starting training for Fold {fold}...\")\n","\n","# Split the data for the current fold\n","train_idx, val_idx = folds[fold]\n","x_train_table, x_val_table = x_train_val_table[train_idx], x_train_val_table[val_idx]\n","x_train_image, x_val_image = x_train_val_image[train_idx], x_train_val_image[val_idx]\n","y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n","\n","batch_size=2\n","\n","# Create TensorFlow datasets\n","train_dataset = create_dataset(x_train_table, x_train_image, y_train, batch_size).prefetch(tf.data.AUTOTUNE)\n","val_dataset = create_dataset(x_val_table, x_val_image, y_val, batch_size).prefetch(tf.data.AUTOTUNE)\n","\n","# Clear the default graph and reset the session to free memory\n","tf.keras.backend.clear_session()\n","\n","# Initialize the model\n","tf.random.set_seed(42)\n","model = multimodal_model(tabular_model, image_model, fold)\n","\n","# Compile the model\n","model.compile(\n","    loss=\"binary_crossentropy\",\n","    optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n","    metrics=[tf.keras.metrics.AUC(name=\"auc\"), tf.keras.metrics.Recall(name=\"recall\")]\n",")\n","\n","# Define callbacks\n","checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=os.path.join(checkpoint_folder, f'fold_{fold}_{{epoch:03d}}.keras'),\n","    save_best_only=False\n",")\n","\n","# Train the model\n","history = model.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=50,\n","    steps_per_epoch=len(y_train) // batch_size,\n","    validation_steps=len(y_val) // batch_size,\n","    callbacks=[checkpoint_cb],\n","    verbose=1\n",")\n","\n","# Find the best epoch (based on validation AUC)\n","best_epoch = np.argmax(history.history['val_auc']) + 1\n","best_auc = np.max(history.history['val_auc'])\n","best_model_path = os.path.join(checkpoint_folder, f'fold_{fold}_{best_epoch:03d}.keras')\n","\n","# Save the best model path\n","if os.path.exists(os.path.join(checkpoint_folder, \"best_models.pkl\")):\n","    # Load existing list\n","    with open(os.path.join(checkpoint_folder, \"best_models.pkl\"), \"rb\") as f:\n","        best_models = pickle.load(f)\n","else:\n","    best_models = []\n","\n","best_models.append(best_model_path)\n","\n","# Save the updated list\n","with open(os.path.join(checkpoint_folder, \"best_models.pkl\"), \"wb\") as f:\n","    pickle.dump(best_models, f)\n","\n","# Print results\n","print(f\"Best validation AUC for fold {fold}: {best_auc:.4f} at epoch {best_epoch}\")\n","print(f\"Best model for fold {fold} saved at: {best_model_path}\")\n","\n","# Plot the training history for this fold\n","plot_fold_history(history, fold)"],"metadata":{"id":"c-ZeiBB3gBF7"},"id":"c-ZeiBB3gBF7","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training: fold 2"],"metadata":{"id":"ySRN4IzggGIq"},"id":"ySRN4IzggGIq"},{"cell_type":"code","source":["fold = 2\n","\n","# Display fold number at training start\n","print(f\"Starting training for Fold {fold}...\")\n","\n","# Split the data for the current fold\n","train_idx, val_idx = folds[fold]\n","x_train_table, x_val_table = x_train_val_table[train_idx], x_train_val_table[val_idx]\n","x_train_image, x_val_image = x_train_val_image[train_idx], x_train_val_image[val_idx]\n","y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n","\n","batch_size=2\n","\n","# Create TensorFlow datasets\n","train_dataset = create_dataset(x_train_table, x_train_image, y_train, batch_size).prefetch(tf.data.AUTOTUNE)\n","val_dataset = create_dataset(x_val_table, x_val_image, y_val, batch_size).prefetch(tf.data.AUTOTUNE)\n","\n","# Clear the default graph and reset the session to free memory\n","tf.keras.backend.clear_session()\n","\n","# Initialize the model\n","tf.random.set_seed(42)\n","model = multimodal_model(tabular_model, image_model, fold)\n","\n","# Compile the model\n","model.compile(\n","    loss=\"binary_crossentropy\",\n","    optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n","    metrics=[tf.keras.metrics.AUC(name=\"auc\"), tf.keras.metrics.Recall(name=\"recall\")]\n",")\n","\n","# Define callbacks\n","checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=os.path.join(checkpoint_folder, f'fold_{fold}_{{epoch:03d}}.keras'),\n","    save_best_only=False\n",")\n","\n","# Train the model\n","history = model.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=50,\n","    steps_per_epoch=len(y_train) // batch_size,\n","    validation_steps=len(y_val) // batch_size,\n","    callbacks=[checkpoint_cb],\n","    verbose=1\n",")\n","\n","# Find the best epoch (based on validation AUC)\n","best_epoch = np.argmax(history.history['val_auc']) + 1\n","best_auc = np.max(history.history['val_auc'])\n","best_model_path = os.path.join(checkpoint_folder, f'fold_{fold}_{best_epoch:03d}.keras')\n","\n","# Save the best model path\n","if os.path.exists(os.path.join(checkpoint_folder, \"best_models.pkl\")):\n","    # Load existing list\n","    with open(os.path.join(checkpoint_folder, \"best_models.pkl\"), \"rb\") as f:\n","        best_models = pickle.load(f)\n","else:\n","    best_models = []\n","\n","best_models.append(best_model_path)\n","\n","# Save the updated list\n","with open(os.path.join(checkpoint_folder, \"best_models.pkl\"), \"wb\") as f:\n","    pickle.dump(best_models, f)\n","\n","# Print results\n","print(f\"Best validation AUC for fold {fold}: {best_auc:.4f} at epoch {best_epoch}\")\n","print(f\"Best model for fold {fold} saved at: {best_model_path}\")\n","\n","# Plot the training history for this fold\n","plot_fold_history(history, fold)"],"metadata":{"id":"inNb9g1WgHcO"},"id":"inNb9g1WgHcO","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training: fold 3"],"metadata":{"id":"J-DLSZHDgIBZ"},"id":"J-DLSZHDgIBZ"},{"cell_type":"code","source":["fold = 3\n","\n","# Display fold number at training start\n","print(f\"Starting training for Fold {fold}...\")\n","\n","# Split the data for the current fold\n","train_idx, val_idx = folds[fold]\n","x_train_table, x_val_table = x_train_val_table[train_idx], x_train_val_table[val_idx]\n","x_train_image, x_val_image = x_train_val_image[train_idx], x_train_val_image[val_idx]\n","y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n","\n","batch_size=2\n","\n","# Create TensorFlow datasets\n","train_dataset = create_dataset(x_train_table, x_train_image, y_train, batch_size).prefetch(tf.data.AUTOTUNE)\n","val_dataset = create_dataset(x_val_table, x_val_image, y_val, batch_size).prefetch(tf.data.AUTOTUNE)\n","\n","# Clear the default graph and reset the session to free memory\n","tf.keras.backend.clear_session()\n","\n","# Initialize the model\n","tf.random.set_seed(42)\n","model = multimodal_model(tabular_model, image_model, fold)\n","\n","# Compile the model\n","model.compile(\n","    loss=\"binary_crossentropy\",\n","    optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n","    metrics=[tf.keras.metrics.AUC(name=\"auc\"), tf.keras.metrics.Recall(name=\"recall\")]\n",")\n","\n","# Define callbacks\n","checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=os.path.join(checkpoint_folder, f'fold_{fold}_{{epoch:03d}}.keras'),\n","    save_best_only=False\n",")\n","\n","# Train the model\n","history = model.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=50,\n","    steps_per_epoch=len(y_train) // batch_size,\n","    validation_steps=len(y_val) // batch_size,\n","    callbacks=[checkpoint_cb],\n","    verbose=1\n",")\n","\n","# Find the best epoch (based on validation AUC)\n","best_epoch = np.argmax(history.history['val_auc']) + 1\n","best_auc = np.max(history.history['val_auc'])\n","best_model_path = os.path.join(checkpoint_folder, f'fold_{fold}_{best_epoch:03d}.keras')\n","\n","# Save the best model path\n","if os.path.exists(os.path.join(checkpoint_folder, \"best_models.pkl\")):\n","    # Load existing list\n","    with open(os.path.join(checkpoint_folder, \"best_models.pkl\"), \"rb\") as f:\n","        best_models = pickle.load(f)\n","else:\n","    best_models = []\n","\n","best_models.append(best_model_path)\n","\n","# Save the updated list\n","with open(os.path.join(checkpoint_folder, \"best_models.pkl\"), \"wb\") as f:\n","    pickle.dump(best_models, f)\n","\n","# Print results\n","print(f\"Best validation AUC for fold {fold}: {best_auc:.4f} at epoch {best_epoch}\")\n","print(f\"Best model for fold {fold} saved at: {best_model_path}\")\n","\n","# Plot the training history for this fold\n","plot_fold_history(history, fold)"],"metadata":{"id":"145b5-kRgJV2"},"id":"145b5-kRgJV2","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training: fold 4"],"metadata":{"id":"qBxp2FOfgJsZ"},"id":"qBxp2FOfgJsZ"},{"cell_type":"code","source":["fold = 4\n","\n","# Display fold number at training start\n","print(f\"Starting training for Fold {fold}...\")\n","\n","# Split the data for the current fold\n","train_idx, val_idx = folds[fold]\n","x_train_table, x_val_table = x_train_val_table[train_idx], x_train_val_table[val_idx]\n","x_train_image, x_val_image = x_train_val_image[train_idx], x_train_val_image[val_idx]\n","y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n","\n","batch_size=2\n","\n","# Create TensorFlow datasets\n","train_dataset = create_dataset(x_train_table, x_train_image, y_train, batch_size).prefetch(tf.data.AUTOTUNE)\n","val_dataset = create_dataset(x_val_table, x_val_image, y_val, batch_size).prefetch(tf.data.AUTOTUNE)\n","\n","# Clear the default graph and reset the session to free memory\n","tf.keras.backend.clear_session()\n","\n","# Initialize the model\n","tf.random.set_seed(42)\n","model = multimodal_model(tabular_model, image_model, fold)\n","\n","# Compile the model\n","model.compile(\n","    loss=\"binary_crossentropy\",\n","    optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n","    metrics=[tf.keras.metrics.AUC(name=\"auc\"), tf.keras.metrics.Recall(name=\"recall\")]\n",")\n","\n","# Define callbacks\n","checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=os.path.join(checkpoint_folder, f'fold_{fold}_{{epoch:03d}}.keras'),\n","    save_best_only=False\n",")\n","\n","# Train the model\n","history = model.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=50,\n","    steps_per_epoch=len(y_train) // batch_size,\n","    validation_steps=len(y_val) // batch_size,\n","    callbacks=[checkpoint_cb],\n","    verbose=1\n",")\n","\n","# Find the best epoch (based on validation AUC)\n","best_epoch = np.argmax(history.history['val_auc']) + 1\n","best_auc = np.max(history.history['val_auc'])\n","best_model_path = os.path.join(checkpoint_folder, f'fold_{fold}_{best_epoch:03d}.keras')\n","\n","# Save the best model path\n","if os.path.exists(os.path.join(checkpoint_folder, \"best_models.pkl\")):\n","    # Load existing list\n","    with open(os.path.join(checkpoint_folder, \"best_models.pkl\"), \"rb\") as f:\n","        best_models = pickle.load(f)\n","else:\n","    best_models = []\n","\n","best_models.append(best_model_path)\n","\n","# Save the updated list\n","with open(os.path.join(checkpoint_folder, \"best_models.pkl\"), \"wb\") as f:\n","    pickle.dump(best_models, f)\n","\n","# Print results\n","print(f\"Best validation AUC for fold {fold}: {best_auc:.4f} at epoch {best_epoch}\")\n","print(f\"Best model for fold {fold} saved at: {best_model_path}\")\n","\n","# Plot the training history for this fold\n","plot_fold_history(history, fold)"],"metadata":{"id":"K3nBwSVJgMEK"},"id":"K3nBwSVJgMEK","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Ensemble Prediction with training and validation data without data augmentation (rawTrainVal set) for optimal threshold determination"],"metadata":{"id":"xqtXgzTmxeYy"},"id":"xqtXgzTmxeYy"},{"cell_type":"code","execution_count":null,"id":"ELlxUwiCatvH","metadata":{"id":"ELlxUwiCatvH"},"outputs":[],"source":["train_val_predictions = []  # Store predictions from all folds for rawTrainVal set\n","\n","print(\"rawTrainVal Metrics for Each Fold:\")\n","for fold, model_path in enumerate(best_models):\n","    print(f\"\\nFold {fold} rawTrainVal Metrics:\")\n","\n","    # Load the best model for this fold\n","    model = tf.keras.models.load_model(model_path)\n","\n","    # Predict on the rawTrainVal dataset\n","    y_pred = model.predict(\n","        [x_train_val_table_raw, x_train_val_image_raw],  # Input includes both table and image raw data\n","        batch_size=2\n","    )\n","    y_pred_binary = (y_pred >= 0.5).astype(int)  # Convert probabilities to binary predictions\n","\n","    # Compute confusion matrix\n","    cm = confusion_matrix(y_train_val_raw.squeeze(), y_pred_binary)\n","    tn, fp, fn, tp = cm.ravel()\n","\n","    # Compute metrics\n","    auc_value = roc_auc_score(y_train_val_raw.squeeze(), y_pred)\n","    recall = recall_score(y_train_val_raw.squeeze(), y_pred_binary)\n","    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0  # Handle division by zero\n","\n","    # Print results for the fold\n","    print(f\"Confusion Matrix:\\n{cm}\")\n","    print(f\"AUC: {auc_value:.4f}\")\n","    print(f\"Recall: {recall:.4f}\")\n","    print(f\"Specificity: {specificity:.4f}\")\n","\n","    # Store fold predictions\n","    train_val_predictions.append(y_pred.squeeze())\n","\n","# Ensemble predictions (average predictions across all folds for rawTrainVal dataset)\n","averaged_train_val_predictions = np.mean(train_val_predictions, axis=0)\n","\n","# ------------------------- Compute Optimal Threshold -------------------------\n","# Compute ROC curve and AUC for the Training+Validation dataset\n","fpr, tpr, thresholds = roc_curve(y_train_val_raw.squeeze(), averaged_train_val_predictions)\n","roc_auc_train_val = auc(fpr, tpr)\n","\n","# Compute Specificity (1 - FPR)\n","specificity = 1 - fpr\n","\n","# Compute Youden's J statistic\n","j_scores = tpr + specificity - 1\n","\n","# Find the optimal threshold for Training+Validation data\n","optimal_idx = np.argmax(j_scores)\n","optimal_threshold = thresholds[optimal_idx]\n","\n","print(f\"\\nOptimal Threshold from Training+Validation Data: {optimal_threshold:.4f}\")\n","print(f\"AUC (Training+Validation): {roc_auc_train_val:.4f}\")\n","print(f\"Recall at Optimal Threshold: {tpr[optimal_idx]:.4f}\")\n","print(f\"Specificity at Optimal Threshold: {specificity[optimal_idx]:.4f}\")\n","\n","# Final evaluation on rawTrainVal dataset with Default Threshold\n","final_predictions_train_val = (averaged_train_val_predictions >= 0.5).astype(int)\n","final_cm_train_val = confusion_matrix(y_train_val_raw.squeeze(), final_predictions_train_val)\n","tn, fp, fn, tp = final_cm_train_val.ravel()\n","final_auc_train_val = roc_auc_score(y_train_val_raw.squeeze(), averaged_train_val_predictions)\n","final_recall_train_val = tp / (tp + fn)\n","final_specificity_train_val = tn / (tn + fp)\n","\n","print(\"\\nFinal Ensemble rawTrainVal Metrics (Default Threshold 0.5):\")\n","print(f\"Confusion Matrix:\\n{final_cm_train_val}\")\n","print(f\"AUC: {final_auc_train_val:.4f}\")\n","print(f\"Recall: {final_recall_train_val:.4f}\")\n","print(f\"Specificity: {final_specificity_train_val:.4f}\")\n","\n","# Final evaluation on rawTrainVal dataset with Optimal Threshold\n","final_predictions_train_val_optimal = (averaged_train_val_predictions >= optimal_threshold).astype(int)\n","final_cm_train_val_optimal = confusion_matrix(y_train_val_raw.squeeze(), final_predictions_train_val_optimal)\n","tn_optimal, fp_optimal, fn_optimal, tp_optimal = final_cm_train_val_optimal.ravel()\n","final_recall_train_val_optimal = tp_optimal / (tp_optimal + fn_optimal)\n","final_specificity_train_val_optimal = tn_optimal / (tn_optimal + fp_optimal)\n","\n","print(\"\\nFinal Ensemble rawTrainVal Metrics (Optimal Threshold):\")\n","print(f\"Confusion Matrix:\\n{final_cm_train_val_optimal}\")\n","print(f\"Recall: {final_recall_train_val_optimal:.4f}\")\n","print(f\"Specificity: {final_specificity_train_val_optimal:.4f}\")"]},{"cell_type":"markdown","source":["# **Test**"],"metadata":{"id":"i5ArK9wcJ_fz"},"id":"i5ArK9wcJ_fz"},{"cell_type":"markdown","source":["## Ensemble Prediction with test data"],"metadata":{"id":"yiSpYOSkyOq8"},"id":"yiSpYOSkyOq8"},{"cell_type":"code","execution_count":null,"id":"70rGWicEatsS","metadata":{"id":"70rGWicEatsS"},"outputs":[],"source":["test_predictions = []  # Store predictions from all folds for the test dataset\n","\n","print(\"\\nTest Metrics for Each Fold:\")\n","for fold, model_path in enumerate(best_models):\n","    print(f\"\\nFold {fold} Test Metrics:\")\n","\n","    # Load the best model for this fold\n","    model = tf.keras.models.load_model(model_path)\n","\n","    # Predict on the test dataset\n","    y_pred = model.predict(\n","        [x_test_table, x_test_image],  # Input includes both table and image test data\n","        batch_size=2\n","    )\n","    y_pred_binary = (y_pred >= 0.5).astype(int)  # Convert probabilities to binary predictions\n","\n","    # Compute confusion matrix\n","    cm = confusion_matrix(y_test.squeeze(), y_pred_binary)\n","    tn, fp, fn, tp = cm.ravel()\n","\n","    # Compute metrics\n","    auc_value = roc_auc_score(y_test.squeeze(), y_pred)\n","    recall = recall_score(y_test.squeeze(), y_pred_binary)\n","    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0  # Handle division by zero\n","\n","    # Print results for the fold\n","    print(f\"Confusion Matrix:\\n{cm}\")\n","    print(f\"AUC: {auc_value:.4f}\")\n","    print(f\"Recall: {recall:.4f}\")\n","    print(f\"Specificity: {specificity:.4f}\")\n","\n","    # Store fold predictions\n","    test_predictions.append(y_pred.squeeze())\n","\n","# Ensemble predictions (average predictions across all folds for the test dataset)\n","averaged_test_predictions = np.mean(test_predictions, axis=0)\n","\n","# ------------------------- Final Evaluation on Test Dataset -------------------------\n","# Default Threshold (0.5)\n","final_predictions_test = (averaged_test_predictions >= 0.5).astype(int)\n","final_cm_test = confusion_matrix(y_test.squeeze(), final_predictions_test)\n","tn, fp, fn, tp = final_cm_test.ravel()\n","final_auc_test = roc_auc_score(y_test.squeeze(), averaged_test_predictions)\n","final_recall_test = tp / (tp + fn)\n","final_specificity_test = tn / (tn + fp)\n","\n","print(\"\\nFinal Ensemble Test Metrics (Default Threshold 0.5):\")\n","print(f\"Confusion Matrix:\\n{final_cm_test}\")\n","print(f\"AUC: {final_auc_test:.4f}\")\n","print(f\"Recall: {final_recall_test:.4f}\")\n","print(f\"Specificity: {final_specificity_test:.4f}\")\n","\n","# Optimal Threshold\n","final_predictions_test_optimal = (averaged_test_predictions >= optimal_threshold).astype(int)\n","final_cm_test_optimal = confusion_matrix(y_test.squeeze(), final_predictions_test_optimal)\n","tn_optimal_test, fp_optimal_test, fn_optimal_test, tp_optimal_test = final_cm_test_optimal.ravel()\n","final_recall_test_optimal = tp_optimal_test / (tp_optimal_test + fn_optimal_test)\n","final_specificity_test_optimal = tn_optimal_test / (tn_optimal_test + fp_optimal_test)\n","\n","print(\"\\nFinal Ensemble Test Metrics (Optimal Threshold):\")\n","print(f\"Confusion Matrix:\\n{final_cm_test_optimal}\")\n","print(f\"Recall: {final_recall_test_optimal:.4f}\")\n","print(f\"Specificity: {final_specificity_test_optimal:.4f}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":5}