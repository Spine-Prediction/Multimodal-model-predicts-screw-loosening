{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4Lv41zpUMDLL",
   "metadata": {
    "id": "4Lv41zpUMDLL"
   },
   "source": [
    "# nnUNet, extraction of whole vertebra and vertebral body images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JGTho2v8Ox19",
   "metadata": {
    "id": "JGTho2v8Ox19"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import nibabel as nib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FJZoeLwQK8O3",
   "metadata": {
    "id": "FJZoeLwQK8O3"
   },
   "outputs": [],
   "source": [
    "!pip install nnunetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5T9qhgOwLcbE",
   "metadata": {
    "id": "5T9qhgOwLcbE"
   },
   "outputs": [],
   "source": [
    "!pip install -U triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TXSERhstK8Lz",
   "metadata": {
    "id": "TXSERhstK8Lz"
   },
   "outputs": [],
   "source": [
    "# Define dataset details\n",
    "task_name = 'Dataset001_spine'\n",
    "base_dir = 'PATH/nnUNet_raw_data'  # Replace 'PATH' with the actual base directory\n",
    "task_dir = os.path.join(base_dir, task_name)\n",
    "imagesTs_dir = os.path.join(task_dir, 'imagesTs')\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(imagesTs_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7Dy2oY_5K8DY",
   "metadata": {
    "id": "7Dy2oY_5K8DY"
   },
   "outputs": [],
   "source": [
    "# Define environment variables for nnUNet's required paths\n",
    "os.environ['nnUNet_raw'] = 'PATH/nnUNet_raw_data'\n",
    "os.environ['nnUNet_preprocessed'] = 'PATH/nnUNet_preprocessed'\n",
    "os.environ['nnUNet_results'] = 'PATH/nnUNet_results'\n",
    "\n",
    "# Ensure directories exist by creating them if they don't\n",
    "os.makedirs(os.environ['nnUNet_raw'], exist_ok=True)\n",
    "os.makedirs(os.environ['nnUNet_preprocessed'], exist_ok=True)\n",
    "os.makedirs(os.environ['nnUNet_results'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RL4_t9v7_85D",
   "metadata": {
    "id": "RL4_t9v7_85D"
   },
   "outputs": [],
   "source": [
    "# Display available options for nnUNet's best model selection\n",
    "!nnUNetv2_find_best_configuration -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0B1keSea_S4F",
   "metadata": {
    "id": "0B1keSea_S4F"
   },
   "outputs": [],
   "source": [
    "# Find the best model configuration using a specific trainer and plan\n",
    "!nnUNetv2_find_best_configuration 001 -tr nnUNetTrainer_500epochs -p nnUNetResEncUNetLPlans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EkHq0_aGZVFB",
   "metadata": {
    "id": "EkHq0_aGZVFB"
   },
   "outputs": [],
   "source": [
    "# Display help menu for the nnUNet inference command\n",
    "!nnUNetv2_predict -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z77dPxj2HKjE",
   "metadata": {
    "id": "z77dPxj2HKjE"
   },
   "outputs": [],
   "source": [
    "# Run inference on test images using 2D model configuration\n",
    "!nnUNetv2_predict -d Dataset001_spine -i \"PATH/nnUNet_raw_data/Dataset001_spine/imagesTs\" -o \"PATH1\" -f  0 1 2 3 4 -tr nnUNetTrainer_500epochs -c 2d -p nnUNetResEncUNetLPlans --save_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xxUhEvqS5WlP",
   "metadata": {
    "id": "xxUhEvqS5WlP"
   },
   "outputs": [],
   "source": [
    "# Run inference on test images using 3D full-resolution model configuration\n",
    "!nnUNetv2_predict -d Dataset001_spine -i \"PATH/nnUNet_raw_data/Dataset001_spine/imagesTs\" -o \"PATH2\" -f  0 1 2 3 4 -tr nnUNetTrainer_500epochs -c 3d_fullres -p nnUNetResEncUNetLPlans --save_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5yBWrGz5Wd4",
   "metadata": {
    "id": "a5yBWrGz5Wd4"
   },
   "outputs": [],
   "source": [
    "# Combine the outputs of the 2D and 3D full-resolution models to improve accuracy\n",
    "!nnUNetv2_ensemble -i \"PATH1\" \"PATH2\" -o \"PATH3\" -np 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "huiUfXiubgpb",
   "metadata": {
    "id": "huiUfXiubgpb"
   },
   "source": [
    "### Create and save extracted images in NIfTI format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fAVo9RTc15Mx",
   "metadata": {
    "id": "fAVo9RTc15Mx"
   },
   "outputs": [],
   "source": [
    "# Define the paths to input and output folders\n",
    "folder1 = \"PATH/nnUNet_raw_data/Dataset001_spine/imagesTs\"\n",
    "folder2 = \"PATH3\"\n",
    "output_folder = \"PATH4\"\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get sorted lists of files from both folders\n",
    "files1 = sorted([f for f in os.listdir(folder1) if f.endswith('.nii.gz')])\n",
    "files2 = sorted([f for f in os.listdir(folder2) if f.endswith('.nii.gz')])\n",
    "\n",
    "# Ensure that both folders contain the same number of files\n",
    "if len(files1) != len(files2):\n",
    "    raise ValueError(\"The two folders must contain the same number of files!\")\n",
    "\n",
    "# Process each pair of files\n",
    "for file1, file2 in zip(files1, files2):\n",
    "    # Load the NIfTI files\n",
    "    img1 = nib.load(os.path.join(folder1, file1))\n",
    "    img2 = nib.load(os.path.join(folder2, file2))\n",
    "\n",
    "    # Extract the data arrays\n",
    "    data1 = img1.get_fdata()\n",
    "    data2 = img2.get_fdata()\n",
    "\n",
    "    # Multiply the data arrays to apply the segmentation mask\n",
    "    multiplied_data = data1 * data2\n",
    "\n",
    "    # Rotate the resulting data array 90 degrees for proper alignment\n",
    "    rotated_data = np.rot90(multiplied_data)\n",
    "\n",
    "    # Create a new NIfTI image with the rotated data\n",
    "    new_img = nib.Nifti1Image(rotated_data, affine=img1.affine, header=img1.header)\n",
    "\n",
    "    # Save the new image to the output folder\n",
    "    output_path = os.path.join(output_folder, f\"multiplied_rotated_{file1}\")\n",
    "    nib.save(new_img, output_path)\n",
    "\n",
    "    print(f\"Processed and saved: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
