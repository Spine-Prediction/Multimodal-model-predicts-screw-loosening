{"cells":[{"cell_type":"markdown","id":"c5fa9655","metadata":{"id":"c5fa9655"},"source":["# Multimodal 3D imaging + tabular model  \n","*K-fold training → per-fold Isotonic calibration → independent TEST evaluation*\n","\n","This notebook contains an end-to-end pipeline used in a medical imaging research project:\n","\n","1. **K-fold training** of a multimodal model (tabular + 3D-CNN).\n","2. Saving **all epoch checkpoints** and a `best_models.pkl` file (best epoch per fold by validation AUC).\n","3. **Isotonic Regression calibration** (per fold) and **TEST evaluation** with:\n","   - ROC curve + AUC **bootstrap 95% CI**\n","   - Calibration curve (reliability plot)\n","   - Decision Curve Analysis (net benefit)\n","\n","## Quick start\n","1. Edit `data_path_aug` and `checkpoint_folder` in **“Imports & Global Settings”**.\n","2. Run cells from top to bottom.\n","3. Train folds (**Fold 0–4**) by running the fold cells you need. You can stop/restart at any time; the best model paths are tracked in `best_models.pkl`.\n","4. Run the final evaluation cell to generate metrics and plots.\n","\n","## Expected dataset format (`.npz`)\n","The dataset file must include these arrays (names are required):\n","\n","| key | shape (example) | dtype | description |\n","|---|---:|---|---|\n","| `x_train_val_image` | `(N_train, D, H, W, 1)` or `(N_train, D, H, W)` | float32 | 3D volumes (channel-last) |\n","| `x_train_val_table` | `(N_train, F)` | float32 | tabular features |\n","| `y_train_val` | `(N_train,)` | int/bool | binary labels |\n","| `x_test_image` | `(N_test, D, H, W, 1)` or `(N_test, D, H, W)` | float32 | test volumes |\n","| `x_test_table` | `(N_test, F)` | float32 | test features |\n","| `y_test` | `(N_test,)` | int/bool | test labels |\n","\n","If your image arrays do not include a channel dimension, the notebook will add `[..., None]`.\n","\n","## Note on probability calibration\n","In this notebook, the Isotonic model is fit on each fold’s **validation** predictions and applied to:\n","- that fold’s validation set (to build *OOF calibrated* probabilities), and\n","- the test set (to build a calibrated ensemble).\n","\n","For strictly unbiased calibration (especially if calibration itself is a primary endpoint), consider **nested CV** or fitting calibration on an inner split only.\n"]},{"cell_type":"markdown","id":"6e403f18","metadata":{"id":"6e403f18"},"source":["## Environment (optional)\n","\n","This notebook can run locally or on a GPU-enabled environment.\n","\n","Recommended packages:\n","\n","- Python ≥ 3.10\n","- TensorFlow / Keras (GPU recommended for training; **tested with `keras==3.8.0`**)\n","- NumPy, SciPy, scikit-learn, Matplotlib"]},{"cell_type":"code","execution_count":null,"id":"5NLliSSjna0x","metadata":{"id":"5NLliSSjna0x"},"outputs":[],"source":["# If you see version conflicts, uncomment the line below, run the cell, then restart the runtime.\n","# !pip install keras==3.8.0"]},{"cell_type":"markdown","id":"133e3ac4","metadata":{"id":"133e3ac4"},"source":["## Configuration\n","\n","Edit the paths and key hyperparameters in the next code cell (**Imports & Global Settings**):\n","\n","- `data_path_aug` : path to the `.npz` file (train/val + test)\n","- `checkpoint_folder` : output directory for checkpoints and `best_models.pkl`\n","- `NUM_FOLDS`, `EPOCHS`, `BATCH_SIZE`, `LR` : training settings\n"]},{"cell_type":"code","execution_count":null,"id":"71c6412a","metadata":{"id":"71c6412a"},"outputs":[],"source":["# =========================================================\n","# 0) Imports & Global Settings\n","# =========================================================\n","import os\n","import re\n","import glob\n","import time\n","import gc\n","import pickle\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import matplotlib.pyplot as plt\n","\n","from scipy.stats import beta\n","\n","from sklearn.model_selection import KFold\n","from sklearn.isotonic import IsotonicRegression\n","from sklearn.calibration import calibration_curve\n","from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve\n","\n","# -------------------------\n","# Reproducibility\n","# -------------------------\n","SEED = 42\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","\n","# -------------------------\n","# Training settings\n","# -------------------------\n","BATCH_SIZE = 2\n","NUM_FOLDS  = 5\n","EPOCHS     = 50\n","LR         = 5e-4\n","\n","# -------------------------\n","# Calibration / evaluation settings\n","# -------------------------\n","CALIB_N_BINS   = 5\n","CALIB_STRATEGY = \"quantile\"   # \"uniform\" or \"quantile\"\n","\n","CI_ALPHA   = 0.05\n","AUC_N_BOOT = 2000\n","\n","# -------------------------\n","# Paths (EDIT HERE)\n","# -------------------------\n","# You can either:\n","#   (A) set environment variables `DATA_PATH_AUG` and `CHECKPOINT_DIR`, or\n","#   (B) edit the default values below.\n","#\n","# Expected file: a single `.npz` containing train/val + test arrays (see the first markdown cell).\n","data_path_aug = os.environ.get(\"DATA_PATH_AUG\", \"./data/dataset_augmented.npz\")\n","\n","# Where to write checkpoints (`.keras`) and `best_models.pkl`\n","checkpoint_folder = os.environ.get(\"CHECKPOINT_DIR\", \"./checkpoints\")\n","\n","best_models_file = os.path.join(checkpoint_folder, \"best_models.pkl\")\n","os.makedirs(checkpoint_folder, exist_ok=True)\n","\n","print(\"Settings loaded.\")\n","print(\"Python:\", __import__(\"sys\").version.split()[0])\n","print(\"TensorFlow:\", tf.__version__)\n","try:\n","    import keras as keras_pkg  # standalone package (optional)\n","    print(\"keras package:\", getattr(keras_pkg, \"__version__\", \"unknown\"))\n","except Exception:\n","    pass\n","print(\"checkpoint_folder:\", checkpoint_folder)\n","print(\"data_path_aug:\", data_path_aug)\n"]},{"cell_type":"code","execution_count":null,"id":"fecc1e1e","metadata":{"id":"fecc1e1e"},"outputs":[],"source":["# =========================================================\n","# 2) Load data (augmented train/val + test)\n","#    - IMPORTANT: We shuffle train/val ONCE with SEED and reuse the same order\n","#      for both training (fold splits) and evaluation.\n","# =========================================================\n","if not os.path.exists(data_path_aug):\n","    raise FileNotFoundError(f\"Augmented data file not found: {data_path_aug}\")\n","\n","loaded_aug = np.load(data_path_aug)\n","\n","x_train_val_image = loaded_aug[\"x_train_val_image\"]\n","x_train_val_table = loaded_aug[\"x_train_val_table\"]\n","y_train_val       = loaded_aug[\"y_train_val\"].astype(int).ravel()\n","\n","x_test_image = loaded_aug[\"x_test_image\"]\n","x_test_table = loaded_aug[\"x_test_table\"]\n","y_test       = loaded_aug[\"y_test\"].astype(int).ravel()\n","\n","print(\"Loaded augmented data.\")\n","print(\"Train/Val:\", x_train_val_image.shape, x_train_val_table.shape, y_train_val.shape)\n","print(\"Test     :\", x_test_image.shape, x_test_table.shape, y_test.shape)\n","\n","# --- shuffle train/val deterministically ---\n","idx = np.arange(len(y_train_val))\n","rng = np.random.default_rng(SEED)\n","rng.shuffle(idx)\n","\n","x_train_val_image = x_train_val_image[idx]\n","x_train_val_table = x_train_val_table[idx]\n","y_train_val       = y_train_val[idx]\n","\n","print(\"After deterministic shuffle (train/val):\", x_train_val_image.shape, x_train_val_table.shape, y_train_val.shape)\n","\n","\n","# Shapes\n","N_FEATURES = x_train_val_table.shape[1]\n","IMG_SHAPE  = (x_train_val_image.shape[1], x_train_val_image.shape[2], x_train_val_image.shape[3], 1)\n","\n","print(\"N_FEATURES:\", N_FEATURES)\n","print(\"IMG_SHAPE :\", IMG_SHAPE)\n","# --- ensure expected dtypes/shapes ---\n","# The training pipeline expects float inputs and channel-last images.\n","x_train_val_image = x_train_val_image.astype(np.float32)\n","x_train_val_table = x_train_val_table.astype(np.float32)\n","x_test_image      = x_test_image.astype(np.float32)\n","x_test_table      = x_test_table.astype(np.float32)\n","\n","# Add channel dimension if missing: (N, D, H, W) -> (N, D, H, W, 1)\n","if x_train_val_image.ndim == 4:\n","    x_train_val_image = x_train_val_image[..., None]\n","if x_test_image.ndim == 4:\n","    x_test_image = x_test_image[..., None]\n"]},{"cell_type":"markdown","id":"f78a6ef2","metadata":{"id":"f78a6ef2"},"source":["## Model definitions (tabular + 3D-CNN + multimodal)\n","\n","This section defines a simple reference architecture:\n","- **Tabular branch**: currently an identity/pass-through (edit to add an MLP if needed).\n","- **Image branch**: a lightweight 3D-CNN that outputs a 1-unit sigmoid probability.\n","- **Multimodal head**: concatenates tabular features and the image probability, then outputs a final sigmoid.\n","\n","Feel free to adjust filters, depth, dropout, and the tabular sub-network to match your task and compute budget.\n"]},{"cell_type":"code","execution_count":null,"id":"de0ffb8d","metadata":{"id":"de0ffb8d"},"outputs":[],"source":["# =========================================================\n","# 3) Model definitions\n","#    - IMPORTANT: We build a *fresh* model per fold to avoid weight sharing across folds.\n","# =========================================================\n","\n","def model_tabular(n_features: int, fold: int):\n","    # Simple NN for tabular input (postoperative day etc.)\n","    inputs = keras.Input((n_features,), name=f\"tabular_input_fold_{fold}\")\n","    x = inputs  # identity (you can add Dense layers here if needed)\n","    return keras.Model(inputs, x, name=f\"TabularModel_Fold_{fold}\")\n","\n","def model_image(img_shape, fold: int):\n","    # 3D CNN for image input\n","    inputs = keras.Input(img_shape, name=f\"image_input_fold_{fold}\")\n","\n","    x = layers.Conv3D(64, 3, kernel_initializer=\"he_normal\", name=f\"conv3d_1_fold_{fold}\")(inputs)\n","    x = layers.BatchNormalization(name=f\"bn_1_fold_{fold}\")(x)\n","    x = layers.Activation(\"relu\", name=f\"relu_1_fold_{fold}\")(x)\n","    x = layers.MaxPool3D(2, name=f\"pool_1_fold_{fold}\")(x)\n","\n","    x = layers.Conv3D(64, 3, kernel_initializer=\"he_normal\", name=f\"conv3d_2_fold_{fold}\")(x)\n","    x = layers.BatchNormalization(name=f\"bn_2_fold_{fold}\")(x)\n","    x = layers.Activation(\"relu\", name=f\"relu_2_fold_{fold}\")(x)\n","    x = layers.MaxPool3D(2, name=f\"pool_2_fold_{fold}\")(x)\n","\n","    x = layers.Conv3D(128, 3, kernel_initializer=\"he_normal\", name=f\"conv3d_3_fold_{fold}\")(x)\n","    x = layers.BatchNormalization(name=f\"bn_3_fold_{fold}\")(x)\n","    x = layers.Activation(\"relu\", name=f\"relu_3_fold_{fold}\")(x)\n","    x = layers.MaxPool3D(2, name=f\"pool_3_fold_{fold}\")(x)\n","\n","    x = layers.Conv3D(256, 3, kernel_initializer=\"he_normal\", name=f\"conv3d_4_fold_{fold}\")(x)\n","    x = layers.BatchNormalization(name=f\"bn_4_fold_{fold}\")(x)\n","    x = layers.Activation(\"relu\", name=f\"relu_4_fold_{fold}\")(x)\n","    x = layers.MaxPool3D(2, name=f\"pool_4_fold_{fold}\")(x)\n","\n","    x = layers.GlobalAveragePooling3D(name=f\"gap_fold_{fold}\")(x)\n","    x = layers.Dense(512, activation=\"relu\", kernel_initializer=\"he_normal\", name=f\"dense_1_fold_{fold}\")(x)\n","    x = layers.Dropout(0.3, name=f\"dropout_1_fold_{fold}\")(x)\n","\n","    # Keep sigmoid head as in the original notebook (used as a feature in multimodal)\n","    outputs = layers.Dense(1, activation=\"sigmoid\", name=f\"image_prob_fold_{fold}\")(x)\n","    return keras.Model(inputs, outputs, name=f\"ImageModel_Fold_{fold}\")\n","\n","def multimodal_model(n_features: int, img_shape, fold: int):\n","    # Combine tabular + image branches\n","    tab_m = model_tabular(n_features, fold)\n","    img_m = model_image(img_shape, fold)\n","\n","    combined = layers.Concatenate(name=f\"concat_fold_{fold}\")([tab_m.output, img_m.output])\n","    outputs  = layers.Dense(1, activation=\"sigmoid\", name=f\"output_fold_{fold}\")(combined)\n","\n","    model = keras.Model(inputs=[tab_m.input, img_m.input], outputs=outputs, name=f\"MultimodalModel_Fold_{fold}\")\n","    return model\n","\n","# quick sanity check (fold 0)\n","tmp = multimodal_model(N_FEATURES, IMG_SHAPE, fold=0)\n","tmp.summary()\n","del tmp\n","gc.collect()\n"]},{"cell_type":"markdown","id":"1e3153d5","metadata":{"id":"1e3153d5"},"source":["## Training utilities + KFold splits (no training loop)\n","\n","We create the `KFold` splits **once** and reuse the indices for both training and evaluation.\n","\n","**Why each fold is a separate cell** (instead of a single for-loop):\n","- easier to resume after interruptions (common on Colab)\n","- less GPU memory fragmentation\n","- lets you inspect training curves per fold\n","\n","During training, the notebook saves **all epoch checkpoints** (`fold_{k}_{epoch}.keras`).\n","The best epoch is selected by **validation AUC** and its path is stored in `best_models.pkl`.\n"]},{"cell_type":"code","execution_count":null,"id":"b8b1ccef","metadata":{"id":"b8b1ccef"},"outputs":[],"source":["# =========================================================\n","# 4) Training utilities (tf.data) + deterministic fold splits\n","# =========================================================\n","\n","def plot_fold_history(history, fold):\n","    fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n","    for i, metric in enumerate([\"loss\", \"auc\"]):\n","        ax[i].plot(history.history.get(metric, []), label=\"Train\")\n","        ax[i].plot(history.history.get(\"val_\" + metric, []), label=\"Validation\")\n","        ax[i].set_title(f\"Fold {fold} - {metric.upper()}\")\n","        ax[i].set_xlabel(\"Epochs\")\n","        ax[i].set_ylabel(metric.upper())\n","        ax[i].legend()\n","    plt.tight_layout()\n","    plt.show()\n","\n","def data_generator(x_table, x_image, y, batch_size):\n","    while True:\n","        for start in range(0, len(y), batch_size):\n","            end = start + batch_size\n","            yield ((x_table[start:end], x_image[start:end]), y[start:end])\n","\n","def create_dataset(x_table, x_image, y, batch_size, shuffle=False, seed=SEED):\n","    ds = tf.data.Dataset.from_generator(\n","        lambda: data_generator(x_table, x_image, y, batch_size),\n","        output_signature=(\n","            (\n","                tf.TensorSpec(shape=(None, x_table.shape[1]), dtype=tf.float32),\n","                tf.TensorSpec(shape=(None, x_image.shape[1], x_image.shape[2], x_image.shape[3], 1), dtype=tf.float32),\n","            ),\n","            tf.TensorSpec(shape=(None,), dtype=tf.float32),\n","        ),\n","    )\n","    if shuffle:\n","        ds = ds.shuffle(buffer_size=min(len(y), 2048), seed=seed, reshuffle_each_iteration=True)\n","    return ds\n","\n","# Prepare fold splits ONCE and reuse\n","kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\n","folds = list(kf.split(x_train_val_table))\n","print(f\"Prepared folds: {len(folds)} splits\")\n"]},{"cell_type":"code","execution_count":null,"id":"548d7fdf","metadata":{"id":"548d7fdf"},"outputs":[],"source":["# =========================================================\n","# 5) Train ONE fold (call this from the fold-specific cells below)\n","# =========================================================\n","\n","def _load_best_models_list(path: str, num_folds: int):\n","    if os.path.exists(path):\n","        with open(path, \"rb\") as f:\n","            bm = pickle.load(f)\n","        # Accept list or dict\n","        if isinstance(bm, dict):\n","            return [bm.get(i, None) for i in range(num_folds)]\n","        if isinstance(bm, list):\n","            if len(bm) < num_folds:\n","                bm = bm + [None] * (num_folds - len(bm))\n","            return bm[:num_folds]\n","    return [None] * num_folds\n","\n","def _save_best_models_list(path: str, best_models_list):\n","    with open(path, \"wb\") as f:\n","        pickle.dump(best_models_list, f)\n","\n","def train_one_fold(fold: int,\n","                   epochs: int = EPOCHS,\n","                   batch_size: int = BATCH_SIZE,\n","                   lr: float = LR,\n","                   steps_per_epoch_min: int = 1):\n","    print(f\"\\n===== Training fold {fold}/{NUM_FOLDS-1} =====\")\n","\n","    train_idx, val_idx = folds[fold]\n","    x_tr_tab, x_va_tab = x_train_val_table[train_idx], x_train_val_table[val_idx]\n","    x_tr_img, x_va_img = x_train_val_image[train_idx], x_train_val_image[val_idx]\n","    y_tr, y_va         = y_train_val[train_idx], y_train_val[val_idx]\n","\n","    # tf.data datasets\n","    train_ds = create_dataset(x_tr_tab, x_tr_img, y_tr, batch_size, shuffle=True, seed=SEED).prefetch(tf.data.AUTOTUNE)\n","    val_ds   = create_dataset(x_va_tab, x_va_img, y_va, batch_size, shuffle=False).prefetch(tf.data.AUTOTUNE)\n","\n","    # Reset graph / free memory\n","    tf.keras.backend.clear_session()\n","    gc.collect()\n","\n","    # Build a fresh model for this fold\n","    model = multimodal_model(N_FEATURES, IMG_SHAPE, fold=fold)\n","    model.compile(\n","        loss=\"binary_crossentropy\",\n","        optimizer=keras.optimizers.Adam(learning_rate=lr),\n","        metrics=[\n","            tf.keras.metrics.AUC(name=\"auc\"),\n","            tf.keras.metrics.Recall(name=\"recall\"),\n","        ],\n","    )\n","\n","    ckpt_pattern = os.path.join(checkpoint_folder, f\"fold_{fold}_{{epoch:03d}}.keras\")\n","    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n","        filepath=ckpt_pattern,\n","        save_best_only=False,   # keep same behavior as original\n","        verbose=0,\n","    )\n","\n","    steps_per_epoch = max(steps_per_epoch_min, len(y_tr) // batch_size)\n","    val_steps       = max(1, len(y_va) // batch_size)\n","\n","    history = model.fit(\n","        train_ds,\n","        validation_data=val_ds,\n","        epochs=epochs,\n","        steps_per_epoch=steps_per_epoch,\n","        validation_steps=val_steps,\n","        callbacks=[checkpoint_cb],\n","        verbose=1,\n","    )\n","\n","    best_epoch = int(np.argmax(history.history[\"val_auc\"]) + 1)\n","    best_auc   = float(np.max(history.history[\"val_auc\"]))\n","    best_model_path = os.path.join(checkpoint_folder, f\"fold_{fold}_{best_epoch:03d}.keras\")\n","\n","    # Save/update best_models.pkl (index = fold)\n","    best_models = _load_best_models_list(best_models_file, NUM_FOLDS)\n","    best_models[fold] = best_model_path\n","    _save_best_models_list(best_models_file, best_models)\n","\n","    print(f\"Best validation AUC for fold {fold}: {best_auc:.4f} at epoch {best_epoch}\")\n","    print(\"Best model path:\", best_model_path)\n","    print(\"Updated:\", best_models_file)\n","\n","    plot_fold_history(history, fold)\n","\n","    return history\n"]},{"cell_type":"markdown","id":"22a85273","metadata":{"id":"22a85273"},"source":["### Train fold 0\n","\n","Run this cell to train **fold 0**.\n","\n","Tips:\n","- Adjust `EPOCHS`, `BATCH_SIZE`, and `LR` in **Imports & Global Settings**.\n","- The notebook saves all epoch checkpoints and updates `best_models.pkl` with the best epoch (by validation AUC).\n","- You can interrupt and resume later; already-trained folds do not need to be retrained.\n"]},{"cell_type":"code","execution_count":null,"id":"10e226df","metadata":{"id":"10e226df"},"outputs":[],"source":["history_fold_0 = train_one_fold(0)\n"]},{"cell_type":"markdown","id":"1fe823a1","metadata":{"id":"1fe823a1"},"source":["### Train fold 1\n","\n","Run this cell to train **fold 1**.\n","\n","Tips:\n","- Adjust `EPOCHS`, `BATCH_SIZE`, and `LR` in **Imports & Global Settings**.\n","- The notebook saves all epoch checkpoints and updates `best_models.pkl` with the best epoch (by validation AUC).\n","- You can interrupt and resume later; already-trained folds do not need to be retrained.\n"]},{"cell_type":"code","execution_count":null,"id":"0bcaa530","metadata":{"id":"0bcaa530"},"outputs":[],"source":["history_fold_1 = train_one_fold(1)\n"]},{"cell_type":"markdown","id":"402e2e46","metadata":{"id":"402e2e46"},"source":["### Train fold 2\n","\n","Run this cell to train **fold 2**.\n","\n","Tips:\n","- Adjust `EPOCHS`, `BATCH_SIZE`, and `LR` in **Imports & Global Settings**.\n","- The notebook saves all epoch checkpoints and updates `best_models.pkl` with the best epoch (by validation AUC).\n","- You can interrupt and resume later; already-trained folds do not need to be retrained.\n"]},{"cell_type":"code","execution_count":null,"id":"b35458bf","metadata":{"id":"b35458bf"},"outputs":[],"source":["history_fold_2 = train_one_fold(2)\n"]},{"cell_type":"markdown","id":"d105f27f","metadata":{"id":"d105f27f"},"source":["### Train fold 3\n","\n","Run this cell to train **fold 3**.\n","\n","Tips:\n","- Adjust `EPOCHS`, `BATCH_SIZE`, and `LR` in **Imports & Global Settings**.\n","- The notebook saves all epoch checkpoints and updates `best_models.pkl` with the best epoch (by validation AUC).\n","- You can interrupt and resume later; already-trained folds do not need to be retrained.\n"]},{"cell_type":"code","execution_count":null,"id":"32feac87","metadata":{"id":"32feac87"},"outputs":[],"source":["history_fold_3 = train_one_fold(3)\n"]},{"cell_type":"markdown","id":"a6d78d06","metadata":{"id":"a6d78d06"},"source":["### Train fold 4\n","\n","Run this cell to train **fold 4**.\n","\n","Tips:\n","- Adjust `EPOCHS`, `BATCH_SIZE`, and `LR` in **Imports & Global Settings**.\n","- The notebook saves all epoch checkpoints and updates `best_models.pkl` with the best epoch (by validation AUC).\n","- You can interrupt and resume later; already-trained folds do not need to be retrained.\n"]},{"cell_type":"code","execution_count":null,"id":"b27bf027","metadata":{"id":"b27bf027"},"outputs":[],"source":["history_fold_4 = train_one_fold(4)\n"]},{"cell_type":"markdown","id":"f71aa5b2","metadata":{"id":"f71aa5b2"},"source":["## Isotonic Regression (OOF) + TEST evaluation/plots (AUC, Calibration, DCA)\n","\n","This section performs probability calibration and evaluation:\n","\n","1. Load the best checkpoint for each fold (from `best_models.pkl`, or by scanning `checkpoint_folder` as a fallback).\n","2. For each fold:\n","   - predict on the fold validation split and the test set\n","   - fit **Isotonic Regression** on the validation predictions\n","   - apply the calibrator to the fold validation (OOF) and to the test set\n","3. Aggregate calibrated test predictions by **mean ensembling across folds**.\n","\n","Outputs:\n","- TEST ROC curve + AUC (with stratified bootstrap 95% CI)\n","- Calibration curve (reliability plot)\n","- Decision Curve Analysis (net benefit)\n","\n","If you already have trained models, you may skip the fold training cells and run only this section (make sure `checkpoint_folder` and `best_models.pkl` point to your checkpoints).\n"]},{"cell_type":"code","execution_count":null,"id":"49ddfb89","metadata":{"id":"49ddfb89"},"outputs":[],"source":["# =========================================================\n","# 6) Isotonic Regression (fit on each fold's val) + TEST evaluation\n","#    - uses the SAME `folds` indices as training\n","# =========================================================\n","\n","def sanitize_prob(p, name=\"\", clip01=True):\n","    p = np.asarray(p, dtype=np.float64).ravel()\n","    bad = ~np.isfinite(p)\n","    if bad.any():\n","        print(f\"[sanitize_prob] {name}: {bad.sum()} non-finite values -> replaced with 0.5\")\n","        p[bad] = 0.5\n","    if clip01:\n","        p = np.clip(p, 1e-6, 1 - 1e-6)\n","    return p\n","\n","def bootstrap_auc_ci(y_true, y_prob, n_boot=2000, alpha=0.05, seed=42):\n","    y_true = np.asarray(y_true).astype(int).ravel()\n","    y_prob = sanitize_prob(y_prob, \"bootstrap_auc_ci\", clip01=True)\n","\n","    rng = np.random.default_rng(seed)\n","    aucs = []\n","    pos = np.where(y_true == 1)[0]\n","    neg = np.where(y_true == 0)[0]\n","    if len(pos) == 0 or len(neg) == 0:\n","        return np.nan, (np.nan, np.nan)\n","\n","    for _ in range(n_boot):\n","        samp_pos = rng.choice(pos, size=len(pos), replace=True)\n","        samp_neg = rng.choice(neg, size=len(neg), replace=True)\n","        idx = np.concatenate([samp_pos, samp_neg])\n","        rng.shuffle(idx)\n","        try:\n","            aucs.append(roc_auc_score(y_true[idx], y_prob[idx]))\n","        except Exception:\n","            pass\n","\n","    aucs = np.array(aucs, dtype=float)\n","    auc_mean = float(np.mean(aucs))\n","    lo = float(np.quantile(aucs, alpha / 2))\n","    hi = float(np.quantile(aucs, 1 - alpha / 2))\n","    return auc_mean, (lo, hi)\n","\n","def plot_calibration(y_true, y_prob, n_bins=10, strategy=\"quantile\", title=\"Calibration (TEST)\"):\n","    y_true = np.asarray(y_true).astype(int).ravel()\n","    y_prob = sanitize_prob(y_prob, \"plot_calibration\", clip01=True)\n","    frac_pos, mean_pred = calibration_curve(y_true, y_prob, n_bins=n_bins, strategy=strategy)\n","\n","    plt.figure(figsize=(6, 6))\n","    plt.plot([0, 1], [0, 1], linestyle=\"--\", linewidth=1, label=\"Ideal\")\n","    plt.plot(mean_pred, frac_pos, marker=\"o\", linewidth=2, label=\"Isotonic (TEST)\")\n","    plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n","    plt.xlim(0, 1)\n","    plt.ylim(0, 1)\n","    plt.xlabel(\"Mean predicted probability\")\n","    plt.ylabel(\"Fraction of positives\")\n","    plt.title(title)\n","    plt.grid(True, linestyle=\"--\", alpha=0.5)\n","    plt.legend(loc=\"best\")\n","    plt.tight_layout()\n","    plt.show()\n","\n","def plot_dca(y_true, y_prob, title=\"DCA (TEST)\"):\n","    y_true = np.asarray(y_true).astype(int).ravel()\n","    y_prob = sanitize_prob(y_prob, \"plot_dca\", clip01=True)\n","\n","    thresholds = np.linspace(0.01, 0.99, 100)\n","    n = len(y_true)\n","    prevalence = np.mean(y_true)\n","\n","    nb_model = []\n","    nb_all = []\n","    for pt in thresholds:\n","        y_hat = (y_prob >= pt).astype(int)\n","        tn, fp, fn, tp = confusion_matrix(y_true, y_hat).ravel()\n","        w = pt / (1 - pt)\n","        nb_m = (tp / n) - (fp / n) * w\n","        nb_a = prevalence - (1 - prevalence) * w\n","        nb_model.append(nb_m)\n","        nb_all.append(nb_a)\n","\n","    nb_model = np.array(nb_model)\n","    nb_all = np.array(nb_all)\n","    nb_none = np.zeros_like(nb_model)\n","\n","    plt.figure(figsize=(7, 5))\n","    plt.plot(thresholds, nb_model, linewidth=2, label=\"Isotonic (TEST)\")\n","    plt.plot(thresholds, nb_all, linestyle=\":\", label=\"Treat All\")\n","    plt.plot(thresholds, nb_none, linestyle=\"--\", label=\"Treat None\")\n","\n","    plt.xlim(0, 1)\n","    plt.ylim(-0.1, max(np.max(nb_model), np.max(nb_all)) + 0.05)\n","    plt.xlabel(\"Threshold Probability\")\n","    plt.ylabel(\"Net Benefit\")\n","    plt.title(title)\n","    plt.grid(True, linestyle=\"--\", alpha=0.5)\n","    plt.legend(loc=\"best\")\n","    plt.tight_layout()\n","    plt.show()\n","\n","# ---------------------------------------------------------\n","# Load best model paths (from best_models.pkl) and map fold->path\n","# ---------------------------------------------------------\n","print(\"\\n[Eval] Loading model list...\")\n","if os.path.exists(best_models_file):\n","    with open(best_models_file, \"rb\") as f:\n","        best_models_paths = pickle.load(f)\n","else:\n","    best_models_paths = []\n","\n","# fallback: search folder\n","if isinstance(best_models_paths, list) and len(best_models_paths) == 0:\n","    print(\"  [Warning] best_models.pkl not found/empty. Searching for .keras files...\")\n","    best_models_paths = sorted(glob.glob(os.path.join(checkpoint_folder, \"*.keras\")))\n","\n","if isinstance(best_models_paths, dict):\n","    best_models_paths = [best_models_paths.get(i, None) for i in range(NUM_FOLDS)]\n","\n","print(\"best_models_paths:\", best_models_paths)\n","\n","fold_to_model = {}\n","for p in best_models_paths:\n","    if not p:\n","        continue\n","    m = re.search(r\"fold_(\\d+)\", os.path.basename(p))\n","    if m:\n","        fold_to_model[int(m.group(1))] = p\n","\n","def get_model_path_for_fold(fold: int) -> str:\n","    mp = fold_to_model.get(fold, None)\n","    if mp is None:\n","        raise FileNotFoundError(f\"Model for fold={fold} not found. Train that fold first.\")\n","    return mp\n","\n","# ---------------------------------------------------------\n","# Predict per fold: fit isotonic on val, apply to val (OOF) and test\n","# ---------------------------------------------------------\n","print(\"\\n[Eval] Predicting and applying Isotonic (fit on val, apply to TEST)...\")\n","n_tv = len(y_train_val)\n","oof_iso = np.zeros(n_tv, dtype=np.float32)\n","test_iso_list = []\n","\n","for fold in range(NUM_FOLDS):\n","    print(f\"  Processing Fold {fold+1}/{NUM_FOLDS}...\")\n","    model_path = get_model_path_for_fold(fold)\n","    print(\"    Model:\", model_path)\n","\n","    train_idx, val_idx = folds[fold]\n","\n","    tf.keras.backend.clear_session()\n","    model = tf.keras.models.load_model(model_path, compile=False)\n","\n","    val_prob  = model.predict([x_train_val_table[val_idx], x_train_val_image[val_idx]], batch_size=BATCH_SIZE, verbose=0).ravel()\n","    test_prob = model.predict([x_test_table, x_test_image], batch_size=BATCH_SIZE, verbose=0).ravel()\n","    val_prob  = sanitize_prob(val_prob, f\"val_prob_fold{fold}\")\n","    test_prob = sanitize_prob(test_prob, f\"test_prob_fold{fold}\")\n","\n","    iso = IsotonicRegression(out_of_bounds=\"clip\")\n","    iso.fit(val_prob, y_train_val[val_idx])\n","\n","    val_prob_iso  = sanitize_prob(iso.predict(val_prob),  f\"val_prob_iso_fold{fold}\")\n","    test_prob_iso = sanitize_prob(iso.predict(test_prob), f\"test_prob_iso_fold{fold}\")\n","\n","    oof_iso[val_idx] = val_prob_iso\n","    test_iso_list.append(test_prob_iso.astype(np.float32))\n","\n","    del model\n","    gc.collect()\n","\n","test_prob_iso_ens = np.mean(np.stack(test_iso_list, axis=0), axis=0)\n","\n","# ---------------------------------------------------------\n","# Metrics & plots\n","# ---------------------------------------------------------\n","auc_test = roc_auc_score(y_test, test_prob_iso_ens)\n","auc_mean, (auc_lo, auc_hi) = bootstrap_auc_ci(y_test, test_prob_iso_ens, n_boot=AUC_N_BOOT, alpha=CI_ALPHA, seed=SEED)\n","\n","print(\"\\n[Eval] TEST AUC (Isotonic ensemble):\", f\"{auc_test:.4f}\")\n","print(\"[Eval] TEST AUC bootstrap mean & 95%CI:\", f\"{auc_mean:.4f} ({auc_lo:.4f} - {auc_hi:.4f})\")\n","\n","fpr, tpr, _ = roc_curve(y_test, test_prob_iso_ens)\n","plt.figure(figsize=(6, 6))\n","plt.plot(fpr, tpr, linewidth=2, label=f\"Isotonic (AUC={auc_test:.3f}, 95% CI {auc_lo:.3f}-{auc_hi:.3f})\")\n","plt.plot([0, 1], [0, 1], linestyle=\"--\", linewidth=1, label=\"Chance\")\n","plt.xlim(0, 1)\n","plt.ylim(0, 1)\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC curve (TEST)\")\n","plt.grid(True, linestyle=\"--\", alpha=0.5)\n","plt.legend(loc=\"best\")\n","plt.tight_layout()\n","plt.show()\n","\n","plot_calibration(y_test, test_prob_iso_ens, n_bins=CALIB_N_BINS, strategy=CALIB_STRATEGY,\n","                 title=\"Calibration curve (TEST) - Isotonic ensemble\")\n","plot_dca(y_test, test_prob_iso_ens, title=\"Decision Curve Analysis (TEST) - Isotonic ensemble\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}