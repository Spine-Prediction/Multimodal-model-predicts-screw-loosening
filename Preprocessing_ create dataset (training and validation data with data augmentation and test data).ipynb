{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"1U7dFyguh0mpR_XejohEKS9R-LiiIkOgd","authorship_tag":"ABX9TyMZexHR3eJVZDiRFy4MblWO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"source":["# Install nibabel, a Python library for reading and writing medical imaging data\n","!pip install nibabel"],"cell_type":"code","metadata":{"id":"DyZG83iRm20m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","import os\n","import nibabel as nib\n","import tensorflow as tf\n","from scipy.ndimage import rotate"],"metadata":{"id":"rkzSXKY71x1d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Paths to the CSV files containing postoperative day and clinical characteristics\n","# Example CSV file is uploaded to the repository\n","# Replace \"PATH1\", \"PATH2\", etc., with actual file paths\n","train_p_table = pd.read_csv(\"PATH1\")  # Training data (positive screw loosening)\n","train_n_table = pd.read_csv(\"PATH2\")  # Training data (negative screw loosening)\n","test_p_table = pd.read_csv(\"PATH3\")  # Test data (positive screw loosening)\n","test_n_table = pd.read_csv(\"PATH4\")  # Test data (negative screw loosening)"],"metadata":{"id":"xbUobzB5Iraw"},"execution_count":null,"outputs":[]},{"source":["# Combine all tables to calculate overall mean and standard deviation\n","combined_data = pd.concat([train_p_table, train_n_table, test_p_table, test_n_table])\n","\n","# Calculate mean and standard deviation for \"Age\" and \"Postoperative day\"\n","age_mean = combined_data[\"Age\"].mean()\n","age_std = combined_data[\"Age\"].std()\n","day_mean = combined_data[\"Postoperative day\"].mean()\n","day_std = combined_data[\"Postoperative day\"].std()\n","\n","# Define a function to standardize a column\n","def standardize_column(table, column, mean, std):\n","    table[column] = (table[column] - mean) / std  # Standardization formula\n","\n","# Standardize \"Age\" and \"Postoperative day\" in each table\n","for table in [train_p_table, train_n_table, test_p_table, test_n_table]:\n","    standardize_column(table, \"Age\", age_mean, age_std)\n","    standardize_column(table, \"Postoperative day\", day_mean, day_std)"],"cell_type":"code","metadata":{"id":"Zfrh6ZIKNDBT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Paths to the corresponding NIfTI files\n","train_p_image = \"PATH5\"  # Training image (positive screw loosening)\n","train_n_image = \"PATH6\"  # Training image (negative screw loosening)\n","test_p_image = \"PATH7\"  # Test image (positive screw loosening)\n","test_n_image = \"PATH8\"  # Test image (negative screw loosening)"],"metadata":{"id":"kLbdLxVF23Ny"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_nii_gz_files_to_ndarray(folder_path):\n","    \"\"\"\n","    Load and process all .nii.gz files in a given folder.\n","\n","    - Reads all NIfTI files in the folder.\n","    - Loads and rotates each image to maintain consistent orientation.\n","    - Returns a NumPy array with dimensions (num_files, height, width, depth).\n","    \"\"\"\n","    # Get a sorted list of all NIfTI files in the folder\n","    nii_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.nii.gz')])\n","\n","    if not nii_files:\n","        raise ValueError(\"No .nii.gz files found in the folder!\")\n","\n","    # Load the first file to determine the image shape\n","    sample_file = nib.load(os.path.join(folder_path, nii_files[0]))\n","    x, y, z = sample_file.shape  # Extract dimensions\n","\n","    # Initialize an empty NumPy array with shape (num_files, y, x, z)\n","    num_files = len(nii_files)\n","    rotated_array = np.zeros((num_files, y, x, z), dtype=np.float32)\n","\n","    # Load and process each file\n","    for i, file_name in tqdm(enumerate(nii_files)):\n","        file_path = os.path.join(folder_path, file_name)\n","        nii_data = nib.load(file_path).get_fdata()  # Convert to NumPy array\n","\n","        # Rotate 90 degrees clockwise for alignment\n","        rotated_data = np.rot90(nii_data, k=-1, axes=(0, 1))\n","        rotated_array[i] = rotated_data\n","\n","    return rotated_array"],"metadata":{"id":"_DIoZIvA9h-q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert NIfTI images to NumPy arrays\n","train_p_image = load_nii_gz_files_to_ndarray(train_p_image)\n","train_n_image = load_nii_gz_files_to_ndarray(train_n_image)\n","test_p_image = load_nii_gz_files_to_ndarray(test_p_image)\n","test_n_image = load_nii_gz_files_to_ndarray(test_n_image)"],"metadata":{"id":"aOIU-01123En"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert images to float32 for compatibility with TensorFlow models\n","train_p_image = train_p_image.astype('float32')\n","train_n_image = train_n_image.astype('float32')\n","test_p_image = test_p_image.astype('float32')\n","test_n_image = test_n_image.astype('float32')"],"metadata":{"id":"VvyfpOjr23B8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create augmented data by flipping along the z-axis\n","train_p_image = np.concatenate((train_p_image, np.flip(train_p_image, 2)), axis=0)\n","train_p_image.shape  # Output the new shape"],"metadata":{"id":"N6dNgbxy3cOf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["angles = [-10, 0, 10]  # Rotation angles in degrees\n","\n","# Augmented data container\n","augmented_images = []\n","\n","# Apply rotation to each image\n","for image in tqdm(train_p_image):\n","    for angle in angles:\n","        # Rotate the image along the z-axis (maintains shape)\n","        rotated_image = rotate(image, angle, axes=(0, 1), reshape=False)\n","        augmented_images.append(rotated_image)\n","\n","# Convert list to NumPy array\n","train_p_image = np.array(augmented_images)\n","print(f\"Augmented data shape: {train_p_image.shape}\")"],"metadata":{"id":"a5Vr1HXrpQim"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Duplicate and extend clinical data to match image augmentation\n","train_p_table = np.concatenate((train_p_table, np.copy(train_p_table)), axis=0)\n","train_p_table = np.repeat(train_p_table, repeats=len(angles), axis=0)\n","\n","print(train_p_table.shape)  # Output the new shape\n","np.set_printoptions(threshold=np.inf, linewidth=120)  # Print full array"],"metadata":{"id":"04ob96zQ3cLj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Create labels for training and testing Data\n","label_train_p = np.array([1 for i in range(len(train_p_image))])  # Positive class (screw loosening)\n","label_train_n = np.array([0 for i in range(len(train_n_image))])  # Negative class (no screw loosening)\n","label_test_p = np.array([1 for i in range(len(test_p_image))])  # Positive test labels\n","label_test_n = np.array([0 for i in range(len(test_n_image))])  # Negative test labels"],"metadata":{"id":"MzmW-sbH8ujj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train_val_image = np.concatenate((train_p_image, train_n_image), axis=0)  # Combine training images\n","x_train_val_table = np.concatenate((train_p_table, train_n_table), axis=0)  # Combine clinical data for training\n","y_train_val = np.concatenate((label_train_p, label_train_n), axis=0)  # Combine labels for training\n","\n","x_test_image = np.concatenate((test_p_image, test_n_image), axis=0)  # Combine test images\n","x_test_table = np.concatenate((test_p_table, test_n_table), axis=0)  # Combine clinical data for testing\n","y_test = np.concatenate((label_test_p, label_test_n), axis=0)  # Combine labels for testing"],"metadata":{"id":"U8KdjIf68uhB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Expand image dimensions for TensorFlow compatibility\n","x_train_val_image = tf.expand_dims(x_train_val_image, axis=4)  # Add a channel dimension for training images\n","x_test_image = tf.expand_dims(x_test_image, axis=4)  # Add a channel dimension for test images"],"metadata":{"id":"XeYQWcH58ue3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save processed data as a compressed .npz File\n","np.savez_compressed(\n","    \"PATH9.npz\",\n","    x_train_val_image=x_train_val_image,\n","    x_train_val_table=x_train_val_table,\n","    y_train_val=y_train_val,\n","    x_test_image=x_test_image,\n","    x_test_table=x_test_table,\n","    y_test=y_test\n",")"],"metadata":{"id":"aXNoi2Gp8ubo"},"execution_count":null,"outputs":[]}]}